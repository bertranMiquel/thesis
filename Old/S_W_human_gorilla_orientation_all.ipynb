{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a31f76ba",
   "metadata": {},
   "source": [
    "# Smith-Waterman genome application\n",
    "\n",
    "We will apply the Smith-Waterman algorithm to two specific sequences. In this example, we align the NC_000017.11 Seq 1 scaffold with the whole gorilla genome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "382bd29a-d482-4e45-a546-6d3846e8dc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from enum import IntEnum\n",
    "from datetime import datetime as dt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import xlsxwriter\n",
    "from matplotlib import pyplot as plt\n",
    "import swco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "460d27b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "LIFE97011 - Computing\n",
    "Python Programming - Assessed Exercise No. 3\n",
    "Task: Smith Waterman local alignment\n",
    "@Author: Slaviana Pavlovich\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Assigning the constants for the scores\n",
    "class Score(IntEnum):\n",
    "    # order by value it should be\n",
    "    MATCH = 10      \n",
    "    CONS_GAP = -2   # Want to penalize worst a first gap than a secong gap\n",
    "    FIRST_GAP = -4\n",
    "    MISMATCH = -3\n",
    "    #INV = 0\n",
    "    DUP = 1\n",
    "\n",
    "# Match: 10 , First_gap: -4, cons_gap: -1, mismatch: -5\n",
    "\n",
    "# Assigning the constant values for the traceback\n",
    "class Trace(IntEnum):\n",
    "    STOP = 0\n",
    "    LEFT = 1 \n",
    "    UP = 2\n",
    "    DIAGONAL = 3\n",
    "\n",
    "def excel_reader(specie):\n",
    "    data = pd.read_excel('../Data/Raw/Tables_Filtered_IK.xlsx', specie)\n",
    "    \n",
    "    data['Gene'] = data['Locus'].str.split('(\\d+)').str[0] + data['Strand']\n",
    "    data['Gene_non_or'] = data['Locus'].str.split('(\\d+)').str[0]\n",
    "    data.reset_index(inplace= True)\n",
    "\n",
    "    data = data[data['Gene'].str.contains('LOC') == False]  \n",
    "\n",
    "    return data\n",
    "\n",
    "# Implementing the Smith Waterman local alignment\n",
    "def smith_waterman(seq_1, seq_2):\n",
    "\n",
    "    # Data structure:\n",
    "    # 0: index\n",
    "    # 1: gen + orientation\n",
    "    # 2: gen\n",
    "\n",
    "    row = len(seq_1) + 1\n",
    "    col = len(seq_2) + 1\n",
    "    matrix = np.zeros(shape=(row, col), dtype= int)  \n",
    "    tracing_matrix = np.zeros(shape=(row, col), dtype= int)  \n",
    "\n",
    "    # Initialising the variables to find the highest scoring cell\n",
    "    max_score = -1\n",
    "    max_index = (-1, -1)\n",
    "\n",
    "    diagonal_score = 0\n",
    "    vertical_score = 0\n",
    "    horizontal_score = 0\n",
    "    \n",
    "    # Calculating the scores for all cells in the matrix\n",
    "\n",
    "    for i in range(1, row):\n",
    "        for j in range(1, col):\n",
    "            \n",
    "            # Calculating the diagonal score (match score)\n",
    "            # If there is a match, always win? And then, we can skip all further comparations?\n",
    "            match_value = Score.MATCH if seq_1.iloc[i - 1, 2] == seq_2.iloc[j - 1, 2] else Score.MISMATCH\n",
    "            #Score.INV if seq_1.iloc[i - 1, 2] == seq_2.iloc[j - 1, 2] else  --> No sense, it will make sense if the overall is inversed and then one of them is turned around. So, first, check the overall waz and then compare them.\n",
    "                \n",
    "            diagonal_score = matrix[i - 1, j - 1] + match_value\n",
    "\n",
    "            # Calculating the vertical gap score, penalizing less consecutive gaps and identifying duplicates\n",
    "            #if seq_2.iloc[j-1, 2] == seq_2.iloc[j - 2, 2]:\n",
    "                #vertical_score = matrix[i - 1, j] + Score.DUP elif\n",
    "            if matrix[i - 1, j] == vertical_score:\n",
    "                vertical_score = matrix[i - 1, j] + Score.CONS_GAP\n",
    "            else: vertical_score = matrix[i - 1, j] + Score.FIRST_GAP\n",
    "            \n",
    "            # Calculating the vertical gap score, penalizing consecutive gaps and identifying duplicates\n",
    "            #if seq_1.iloc[i-1, 2] == seq_1.iloc[i-2, 2]:\n",
    "                #horizontal_score = matrix[i, j - 1] + Score.DUP elif\n",
    "            if matrix[i, j - 1] == horizontal_score:\n",
    "                horizontal_score = matrix[i, j - 1] + Score.CONS_GAP\n",
    "            else: horizontal_score = matrix[i, j - 1] + Score.FIRST_GAP\n",
    "            \n",
    "            # Taking the highest score \n",
    "            matrix[i, j] = max(0, diagonal_score, vertical_score, horizontal_score)\n",
    "            \n",
    "            # Tracking where the cell's value is coming from    \n",
    "            if matrix[i, j] == 0: \n",
    "                tracing_matrix[i, j] = Trace.STOP\n",
    "                \n",
    "            elif matrix[i, j] == horizontal_score: \n",
    "                tracing_matrix[i, j] = Trace.LEFT\n",
    "                \n",
    "            elif matrix[i, j] == vertical_score: \n",
    "                tracing_matrix[i, j] = Trace.UP\n",
    "                \n",
    "            elif matrix[i, j] == diagonal_score: \n",
    "                tracing_matrix[i, j] = Trace.DIAGONAL \n",
    "                \n",
    "            # Tracking the cell with the maximum score\n",
    "            # If we want different strings, here we can define a threshold and keep track of all the higher values\n",
    "            if matrix[i, j] >= max_score:\n",
    "                max_index = (i,j)\n",
    "                max_score = matrix[i, j]\n",
    "\n",
    "\n",
    "    # Initialising the variables for tracing\n",
    "    aligned_seq_1 = [ ]\n",
    "    aligned_seq_2 = [ ]\n",
    "    index_seq_1 = [ ]\n",
    "    index_seq_2 = [ ]\n",
    "    (max_i, max_j) = max_index\n",
    "\n",
    "    # Tracing and computing the pathway with the local alignment\n",
    "    #if max_score > 3 * Score.MATCH\n",
    "    while tracing_matrix[max_i, max_j] != Trace.STOP:\n",
    "        if tracing_matrix[max_i, max_j] == Trace.DIAGONAL:\n",
    "            aligned_seq_1.insert(0, seq_1.iloc[max_i - 1, 2])\n",
    "            aligned_seq_2.insert(0, seq_2.iloc[max_j - 1, 2])\n",
    "\n",
    "            index_seq_1.insert(0, seq_1.iloc[max_i - 1, 0])\n",
    "            index_seq_2.insert(0, seq_2.iloc[max_j - 1, 0])\n",
    "\n",
    "            max_i = max_i - 1\n",
    "            max_j = max_j - 1\n",
    "            \n",
    "\n",
    "        elif tracing_matrix[max_i, max_j] == Trace.UP:\n",
    "            aligned_seq_1.insert(0, seq_1.iloc[max_i - 1, 2])\n",
    "            aligned_seq_2.insert(0, '-')\n",
    "\n",
    "            index_seq_1.insert(0, seq_1.iloc[max_i - 1, 0])\n",
    "            index_seq_2.insert(0, '-')\n",
    "\n",
    "            max_i = max_i - 1    \n",
    "            \n",
    "\n",
    "        elif tracing_matrix[max_i, max_j] == Trace.LEFT:\n",
    "            aligned_seq_1.insert(0, '-')\n",
    "            aligned_seq_2.insert(0, seq_2.iloc[max_j - 1, 2])\n",
    "\n",
    "            index_seq_1.insert(0, '-')\n",
    "            index_seq_2.insert(0, seq_2.iloc[max_j - 1, 0])\n",
    "            \n",
    "            max_j = max_j - 1\n",
    "\n",
    "    return aligned_seq_1, aligned_seq_2, index_seq_1, index_seq_2, max_score, max_index, max_i, max_j, matrix\n",
    "\n",
    "def duplicate(all):\n",
    "    for i in range(1, len(all)):\n",
    "        if all.loc[i, 'Result'] == 'Gap':\n",
    "            if (all.loc[i-1, 'Result'] == 'Match') | (all.loc[i-1, 'Result'] == 'Inversion'):\n",
    "                if (all.loc[i-1,'Query Sequence Gene'] == all.loc[i,'Query Sequence Gene']) | (all.loc[i-1,'Target Sequence Gene'] == all.loc[i,'Target Sequence Gene']):\n",
    "                    all.loc[i, 'Result'] = 'Duplicate'\n",
    "\n",
    "                    # Check for consecutives duplicates\n",
    "                    j = i+1\n",
    "                    while((j<len(all)) & (all.loc[j, 'Result'] == 'Gap') & (all.loc[i,'Query Sequence Gene'] == all.loc[j,'Query Sequence Gene']) & (all.loc[i,'Target Sequence Gene'] == all.loc[j,'Target Sequence Gene'])):\n",
    "                        all.loc[j, 'Result'] = 'Duplicate'\n",
    "                        j+=1\n",
    "                    i=j-1\n",
    "    return all\n",
    "\n",
    "def merge(seq_1, seq_2, aligned_seq_1, index_seq_1, aligned_seq_2, index_seq_2):\n",
    "    align_seq_1 = pd.DataFrame({'Original Position' : index_seq_1, 'Gene': aligned_seq_1}).merge(seq_1[['index', '#Replicon Name', 'Replicon Accession', 'Strand']], left_on = 'Original Position', right_on = 'index', how = 'left')\n",
    "    align_seq_2 = pd.DataFrame({'Original Position' : index_seq_2, 'Gene': aligned_seq_2}).merge(seq_2[['index', '#Replicon Name', 'Replicon Accession', 'Strand']], left_on = 'Original Position', right_on = 'index', how = 'left')\n",
    "\n",
    "    align_seq_1.rename(columns={'Original Position': 'Query Sequence Original Position', 'Gene' : 'Query Sequence Gene', '#Replicon Name': 'Query Sequence Replicon Name', 'Replicon Accession' : 'Query Sequence Replicon Accession', 'Strand': 'Query Sequence Orientation'}, inplace = True)\n",
    "    align_seq_2.rename(columns={'Original Position': 'Target Sequence Original Position', 'Gene' : 'Target Sequence Gene', '#Replicon Name': 'Target Sequence Replicon Name', 'Replicon Accession' : 'Target Sequence Replicon Accession', 'Strand': 'Target Sequence Orientation'}, inplace = True)\n",
    "\n",
    "    all = align_seq_1.loc[:, align_seq_1.columns != 'index'].merge(align_seq_2.loc[:, align_seq_2.columns != 'index'], right_index = True, left_index = True)\n",
    "\n",
    "    all['Result'] = np.where(all['Query Sequence Gene'] == all['Target Sequence Gene'],  \n",
    "                    np.where(all['Query Sequence Orientation'] == all['Target Sequence Orientation'], 'Match', 'Inversion'),\n",
    "                    np.where(((all['Query Sequence Gene'] == '-') | (all['Target Sequence Gene'] == '-')),\n",
    "                      'Gap', 'Mismatch'))\n",
    "    \n",
    "    all = all.reindex(\n",
    "            columns = ['Query Sequence Original Position', 'Query Sequence Replicon Name',\n",
    "            'Query Sequence Replicon Accession', 'Query Sequence Orientation', 'Query Sequence Gene', 'Result', 'Target Sequence Gene', 'Target Sequence Orientation',\n",
    "            'Target Sequence Replicon Accession', 'Target Sequence Replicon Name', 'Target Sequence Original Position'])\n",
    "\n",
    "    return all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35133435",
   "metadata": {},
   "outputs": [],
   "source": [
    "human = swco.excel_reader('Human')\n",
    "#gorilla = excel_reader('Gorilla')\n",
    "xen = pd.read_csv('../Data/Intermediate/xenopus_genome_proc.csv')\n",
    "\n",
    "query_specie = 'human'\n",
    "target_specie = 'xenopus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b09380d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order the accessions per number of locus\n",
    "\n",
    "human_acc = human.groupby('Replicon Accession', as_index = False)['Locus'].count()\n",
    "human_acc.rename(columns={'Locus':'# Locus'}, inplace=True)\n",
    "query_acc = human_acc.loc[human_acc['# Locus'] > 9].sort_values('# Locus', ascending = False)\n",
    "query_acc = query_acc['Replicon Accession']\n",
    "query_acc = query_acc.reset_index()\n",
    "\n",
    "# Just consider two accessions to make a test\n",
    "#query_acc = human_acc.loc[(human_acc['Locus'] == 853) | (human_acc['Locus'] == 958), 'Replicon Accession']\n",
    "\n",
    "#query_acc = human_acc.loc[(human_acc['Replicon Accession'].str.contains('NC_000021.9')), 'Replicon Accession'] # |(human_acc['Replicon Accession'].str.contains('NT_167244.2'))\n",
    "#query_acc = query_acc.reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a84c5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xen.rename(columns={'Change':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20a4f305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 73 entries, 0 to 72\n",
      "Data columns (total 2 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   index               73 non-null     int64 \n",
      " 1   Replicon Accession  73 non-null     object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.3+ KB\n"
     ]
    }
   ],
   "source": [
    "query_acc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5aca13b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_acc.loc[query_acc['Replicon Accession'].str.contains('NC_000024.10'), 'index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "966c55bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_seq = xen.loc[:,['index', 'Gene', 'Gene_non_or']]\n",
    "target_seq_name = 'xen' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0a19ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     NC_000001.11\n",
       "1     NC_000019.10\n",
       "2     NC_000002.12\n",
       "3     NC_000011.10\n",
       "4     NC_000017.11\n",
       "          ...     \n",
       "68     NT_187517.1\n",
       "69     NT_187640.1\n",
       "70     NT_187661.1\n",
       "71     NT_187668.1\n",
       "72     NT_187686.1\n",
       "Name: Replicon Accession, Length: 73, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_acc.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16575016",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [13], line 15\u001b[0m\n\u001b[0;32m     10\u001b[0m params \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\n\u001b[0;32m     11\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mDescription\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mParameters\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMatch\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMismatch\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mFirst gap\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mSecond gap\u001b[39m\u001b[39m'\u001b[39m], \n\u001b[0;32m     12\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mValue\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, swco\u001b[39m.\u001b[39mScore\u001b[39m.\u001b[39mMATCH, swco\u001b[39m.\u001b[39mScore\u001b[39m.\u001b[39mMISMATCH, swco\u001b[39m.\u001b[39mScore\u001b[39m.\u001b[39mFIRST_GAP, swco\u001b[39m.\u001b[39mScore\u001b[39m.\u001b[39mCONS_GAP]})\n\u001b[0;32m     14\u001b[0m results \u001b[39m=\u001b[39m []\n\u001b[1;32m---> 15\u001b[0m results \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(data \u001b[39m=\u001b[39;49m {\u001b[39m'\u001b[39;49m\u001b[39mAccession\u001b[39;49m\u001b[39m'\u001b[39;49m:\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m Covered Target sequence\u001b[39;49m\u001b[39m'\u001b[39;49m:\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m Covered Scaffold\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mNumber of consecutive genes\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m})\n\u001b[0;32m     17\u001b[0m \u001b[39mfor\u001b[39;00m acc \u001b[39min\u001b[39;00m query_acc\u001b[39m.\u001b[39miloc[:,\u001b[39m1\u001b[39m]:\n\u001b[0;32m     19\u001b[0m     \u001b[39mprint\u001b[39m(acc)\n",
      "File \u001b[1;32mc:\\Users\\bertr\\anaconda3\\envs\\thesis\\lib\\site-packages\\pandas\\core\\frame.py:636\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    630\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[0;32m    631\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[0;32m    632\u001b[0m     )\n\u001b[0;32m    634\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    635\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 636\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[0;32m    637\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[0;32m    638\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmrecords\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmrecords\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bertr\\anaconda3\\envs\\thesis\\lib\\site-packages\\pandas\\core\\internals\\construction.py:502\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    494\u001b[0m     arrays \u001b[39m=\u001b[39m [\n\u001b[0;32m    495\u001b[0m         x\n\u001b[0;32m    496\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(x\u001b[39m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m    497\u001b[0m         \u001b[39melse\u001b[39;00m x\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m    498\u001b[0m         \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays\n\u001b[0;32m    499\u001b[0m     ]\n\u001b[0;32m    500\u001b[0m     \u001b[39m# TODO: can we get rid of the dt64tz special case above?\u001b[39;00m\n\u001b[1;32m--> 502\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[39m=\u001b[39;49mdtype, typ\u001b[39m=\u001b[39;49mtyp, consolidate\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[1;32mc:\\Users\\bertr\\anaconda3\\envs\\thesis\\lib\\site-packages\\pandas\\core\\internals\\construction.py:120\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    118\u001b[0m     \u001b[39m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m         index \u001b[39m=\u001b[39m _extract_index(arrays)\n\u001b[0;32m    121\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m         index \u001b[39m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\bertr\\anaconda3\\envs\\thesis\\lib\\site-packages\\pandas\\core\\internals\\construction.py:664\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    661\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    663\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m indexes \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m raw_lengths:\n\u001b[1;32m--> 664\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIf using all scalar values, you must pass an index\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    666\u001b[0m \u001b[39melif\u001b[39;00m have_series:\n\u001b[0;32m    667\u001b[0m     index \u001b[39m=\u001b[39m union_indexes(indexes)\n",
      "\u001b[1;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "# Save our results afterwards\n",
    "path = '../Data/S_W_Intermediate/' # + query_specie + '_' + target_specie + '_' + dt.now().strftime('%Y%m%d_%H%M%S') + '.xlsx'\n",
    "timestamp = dt.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = pd.ExcelWriter(path  + query_specie + '_' + target_specie + '_' + timestamp + '.xlsx', engine = 'xlsxwriter')\n",
    "\n",
    "#os.makedirs(path)\n",
    "\n",
    "# Parameters\n",
    "params = []\n",
    "params = pd.DataFrame({\n",
    "    'Description': ['', 'Parameters', 'Match', 'Mismatch', 'First gap', 'Second gap'], \n",
    "    'Value': ['', '', swco.Score.MATCH, swco.Score.MISMATCH, swco.Score.FIRST_GAP, swco.Score.CONS_GAP]})\n",
    "\n",
    "results = []\n",
    "results = pd.DataFrame(data = {'Accession':'', '% Covered Target sequence':'', '% Covered Scaffold': '', 'Number of consecutive genes': ''})\n",
    "\n",
    "for acc in query_acc.iloc[:,1]:\n",
    "\n",
    "    print(acc)\n",
    "    \n",
    "    query_seq = []\n",
    "    query_seq = human.loc[human['Replicon Accession'].str.contains(acc), ['index', 'Gene', 'Gene_non_or']]\n",
    "    query_seq_name = 'human_' + acc\n",
    "    \n",
    "    # Executing the Smith Waterman local alignment algorithm\n",
    "    aligned_query_seq = []\n",
    "    aligned_target_seq = []\n",
    "    index_query_seq = []\n",
    "    index_target_seq = []\n",
    "    matrix = [[]]\n",
    "\n",
    "    tic = time.perf_counter()\n",
    "    aligned_query_seq, aligned_target_seq, index_query_seq, index_target_seq, max_score, max_index, max_i, max_j, matrix = swco.smith_waterman(query_seq, target_seq)\n",
    "    toc = time.perf_counter()\n",
    "\n",
    "    # Time\n",
    "    d = toc - tic\n",
    "    print('Computed in %s'%time.strftime('%H:%M:%S', time.gmtime(d)))\n",
    "\n",
    "    all = []\n",
    "\n",
    "    all = swco.merge(human, xen, aligned_query_seq, index_query_seq, aligned_target_seq, index_target_seq)\n",
    "\n",
    "    all = swco.duplicate(all)\n",
    "\n",
    "    index_query_seq_no_gaps = []\n",
    "    index_target_seq_no_gaps = []\n",
    "    index_query_seq_no_gaps = list(filter(lambda c: c!= '-', index_query_seq))\n",
    "    index_target_seq_no_gaps = list(filter(lambda c: c!= '-', index_target_seq))\n",
    "\n",
    "    summary = []\n",
    "    summary = pd.DataFrame({\n",
    "        'Description' : ['Query Sequence', 'Length Query Sequence', 'Target Sequence', 'Length Target Sequence', 'Score', '', 'Aligned Query Sequence initial position', 'Aligned Query Sequence final position', 'Aligned Query Sequence length', '', 'Aligned Target Sequence initial position', 'Aligned Target Sequence final position', 'Aligned Target Sequence length'],\n",
    "        'Value': [query_seq_name, len(query_seq), target_seq_name, len(target_seq), max_score, '', index_query_seq_no_gaps[0], \n",
    "                    index_query_seq_no_gaps[-1], index_query_seq_no_gaps[-1] - index_query_seq_no_gaps[0], '', index_target_seq_no_gaps[0], \n",
    "                    index_target_seq_no_gaps[-1], index_target_seq_no_gaps[-1] - index_target_seq_no_gaps[0]]\n",
    "    })\n",
    "\n",
    "    summary = pd.concat([summary, params])\n",
    "\n",
    "    aligned_query_seq_no_gaps = []\n",
    "    aligned_target_seq_no_gaps = []\n",
    "    aligned_query_seq_no_gaps = list(filter(lambda c: c!= '-', aligned_query_seq))\n",
    "    aligned_target_seq_no_gaps = list(filter(lambda c: c!= '-', aligned_target_seq))\n",
    "\n",
    "    #KPIs\n",
    "    perc_align_query_seq = len(aligned_query_seq_no_gaps) / len(query_seq)\n",
    "    perc_align_target_seq = len(aligned_target_seq_no_gaps) / len(target_seq)\n",
    "\n",
    "    kpi = []\n",
    "    kpi = pd.DataFrame({\n",
    "        'Description': ['','KPIs','% Covered Target sequence', '% Covered Scaffold', 'Number of consecutive genes', ''], #include where duplicates occur\n",
    "        'Value': ['','', perc_align_target_seq, perc_align_query_seq, len(all), '']\n",
    "    })\n",
    "\n",
    "    result_perc = all.groupby('Result').count() / all.shape[0]\n",
    "    result_perc = result_perc.reset_index().iloc[:,[0,1]]\n",
    "    result_perc.rename(columns = {'Result':'Description', 'Query Sequence Original Position': 'Value'}, inplace=True)\n",
    "\n",
    "    summary = pd.concat([summary, kpi, result_perc]) # summary.append(kpi)\n",
    "\n",
    "    summary.to_excel(writer, sheet_name = 'Summary_' + acc, index = False, header=False)\n",
    "    all.to_excel(writer, sheet_name = 'Comparison_' + acc, index = False)\n",
    "\n",
    "    actual_results = pd.DataFrame(data = {'Accession': acc, '% Covered Target sequence': perc_align_target_seq, '% Covered Scaffold': perc_align_query_seq, 'Number of consecutive genes': len(all)}, index=query_acc.loc[query_acc['Replicon Accession'].str.contains(acc), 'index'])\n",
    "    results = pd.concat([results, actual_results])\n",
    "    \n",
    "    heatmap = sns.heatmap(matrix)\n",
    "    plt.title('Heatmap of ' + target_seq_name + ' vs. ' + query_seq_name, fontsize = 12)\n",
    "    plt.savefig(path + 'Images/' + timestamp + '_' + acc + '.png')\n",
    "    plt.clf()\n",
    "\n",
    "    workbook  = writer.book\n",
    "    worksheet = writer.sheets['Summary_' + acc]\n",
    "    worksheet.insert_image('H2', path + 'Images/' + timestamp + '_' + acc + '.png')\n",
    "\n",
    "    # Remove match parts and clean variables\n",
    "    prev = []\n",
    "    after = []\n",
    "    prev = target_seq.loc[target_seq['index'] < index_target_seq_no_gaps[0] + 1]\n",
    "    after = target_seq.loc[index_target_seq_no_gaps[-1] - 1 < target_seq['index']]\n",
    "\n",
    "    target_seq = pd.concat([prev, after])\n",
    "    del heatmap, perc_align_target_seq, perc_align_query_seq, result_perc\n",
    "\n",
    "results.to_excel(writer, sheet_name = 'Results', index = False)\n",
    "writer.save()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb39123c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligned_query_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "980fd380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.io.excel._xlsxwriter.XlsxWriter at 0x22153a675b0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "778be516",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results.to_excel(path + 'human_gorilla_20221204_145134.xlsx', sheet_name = 'Results', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f4dc658",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bertr\\anaconda3\\envs\\thesis\\lib\\site-packages\\xlsxwriter\\workbook.py:339: UserWarning: Calling close() on already closed file.\n",
      "  warn(\"Calling close() on already closed file.\")\n"
     ]
    }
   ],
   "source": [
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov  4 2022, 13:42:51) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "0e92abe02844fb54062d758795a97b84494055d25efe9d020733c23e9f9966e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

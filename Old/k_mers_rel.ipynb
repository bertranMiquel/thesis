{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from enum import IntEnum\n",
    "from datetime import datetime as dt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import xlsxwriter\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_scaffold(k, specie, scaffold, min):\n",
    "    df_k_mers = pd.read_csv('../Data/Intermediate/' + str(k) + '_mers.csv')\n",
    "\n",
    "    sp_sca = specie + '_' + scaffold\n",
    "\n",
    "    df_query = df_k_mers[df_k_mers['Specie_Scaffold'].str.contains(sp_sca, case=False)]\n",
    "\n",
    "    df_query['Specie_Scaffold'] = df_query['Specie_Scaffold'].str.replace(\"\\['\", \"\")\n",
    "    df_query['Specie_Scaffold'] = df_query['Specie_Scaffold'].str.replace(\"'\\]\", \"\")\n",
    "    \n",
    "    sep = df_query['Specie_Scaffold'].str.split(\"', '\", expand=True)\n",
    "    df_query = sep.merge(df_query[str(k) + '_mers'], left_index=True, right_index=True, how='right')\n",
    "    melt = pd.melt(df_query, id_vars=[str(k) + '_mers']).dropna().drop('variable',1).rename(columns = {'value':'Specie_Scaffold'})\n",
    "    \n",
    "    match = melt.groupby('Specie_Scaffold', as_index=False).count().rename(columns={str(k) + '_mers':'# Appearances'}).sort_values('# Appearances', ascending=False)\n",
    "    match[['Specie', 'Scaffold']] = match['Specie_Scaffold'].str.split(\"_\", n = 1, expand=True)\n",
    "    match = match.loc[match['# Appearances'] > min, ['Specie', 'Scaffold', '# Appearances']]\n",
    "\n",
    "    return match  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bertr\\AppData\\Local\\Temp\\ipykernel_12928\\1810942397.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_query['Specie_Scaffold'] = df_query['Specie_Scaffold'].str.replace(\"\\['\", \"\")\n",
      "C:\\Users\\bertr\\AppData\\Local\\Temp\\ipykernel_12928\\1810942397.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_query['Specie_Scaffold'] = df_query['Specie_Scaffold'].str.replace(\"\\['\", \"\")\n",
      "C:\\Users\\bertr\\AppData\\Local\\Temp\\ipykernel_12928\\1810942397.py:9: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_query['Specie_Scaffold'] = df_query['Specie_Scaffold'].str.replace(\"'\\]\", \"\")\n",
      "C:\\Users\\bertr\\AppData\\Local\\Temp\\ipykernel_12928\\1810942397.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_query['Specie_Scaffold'] = df_query['Specie_Scaffold'].str.replace(\"'\\]\", \"\")\n",
      "C:\\Users\\bertr\\AppData\\Local\\Temp\\ipykernel_12928\\1810942397.py:13: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  melt = pd.melt(df_query, id_vars=[str(k) + '_mers']).dropna().drop('variable',1).rename(columns = {'value':'Specie_Scaffold'})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Specie</th>\n",
       "      <th>Scaffold</th>\n",
       "      <th># Appearances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Human</td>\n",
       "      <td>NC_000005.10</td>\n",
       "      <td>767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Papio</td>\n",
       "      <td>NC_018157.1</td>\n",
       "      <td>531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Gorilla</td>\n",
       "      <td>NC_018429.2</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Monodelphis</td>\n",
       "      <td>NC_008803.1</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Monodelphis</td>\n",
       "      <td>NC_008801.1</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Croco</td>\n",
       "      <td>NW_017728909.1</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Orca</td>\n",
       "      <td>NW_004438453.1</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Koala</td>\n",
       "      <td>NW_018343955.1</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aadvark</td>\n",
       "      <td>NW_006921643.1</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Croco</td>\n",
       "      <td>NW_017728914.1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Alligator M</td>\n",
       "      <td>NW_017712138.1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Orca</td>\n",
       "      <td>NW_004438462.1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Aadvark</td>\n",
       "      <td>NW_006921953.1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aadvark</td>\n",
       "      <td>NW_006921694.1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Koala</td>\n",
       "      <td>NW_018343957.1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Alligator M</td>\n",
       "      <td>NW_017713851.1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aadvark</td>\n",
       "      <td>NW_006921697.1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aadvark</td>\n",
       "      <td>NW_006921691.1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Chrysemys</td>\n",
       "      <td>NW_007281339.1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Chelonia</td>\n",
       "      <td>NW_006646735.1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Alligator M</td>\n",
       "      <td>NW_017707593.1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Aadvark</td>\n",
       "      <td>NW_006921699.1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Orca</td>\n",
       "      <td>NW_004438529.1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Pelodiscus</td>\n",
       "      <td>NW_005871017.1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Pelodiscus</td>\n",
       "      <td>NW_005871047.1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Pogona</td>\n",
       "      <td>NW_018150745.1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Orca</td>\n",
       "      <td>NW_004438436.1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Ostrich</td>\n",
       "      <td>NW_009271620.1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Devil</td>\n",
       "      <td>NW_003816605.1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Koala</td>\n",
       "      <td>NW_018344103.1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aadvark</td>\n",
       "      <td>NW_006921649.1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Orca</td>\n",
       "      <td>NW_004438483.1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Chelonia</td>\n",
       "      <td>NW_006700040.1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Devil</td>\n",
       "      <td>NW_003816604.1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Pogona</td>\n",
       "      <td>NW_018150707.1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Croco</td>\n",
       "      <td>NW_017728886.1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Chrysemys</td>\n",
       "      <td>NW_007359863.1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Chelonia</td>\n",
       "      <td>NW_006598898.1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Alligator M</td>\n",
       "      <td>NW_017713772.1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Chelonia</td>\n",
       "      <td>NW_006658951.1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Devil</td>\n",
       "      <td>NW_003816613.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Aadvark</td>\n",
       "      <td>NW_006921825.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Chrysemys</td>\n",
       "      <td>NW_007281383.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Pogona</td>\n",
       "      <td>NW_018150815.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Specie        Scaffold  # Appearances\n",
       "53        Human    NC_000005.10            767\n",
       "79        Papio     NC_018157.1            531\n",
       "52      Gorilla     NC_018429.2            310\n",
       "65  Monodelphis     NC_008803.1             93\n",
       "64  Monodelphis     NC_008801.1             77\n",
       "38        Croco  NW_017728909.1             59\n",
       "67         Orca  NW_004438453.1             57\n",
       "57        Koala  NW_018343955.1             41\n",
       "0       Aadvark  NW_006921643.1             37\n",
       "39        Croco  NW_017728914.1             31\n",
       "16  Alligator M  NW_017712138.1             31\n",
       "68         Orca  NW_004438462.1             24\n",
       "11      Aadvark  NW_006921953.1             23\n",
       "3       Aadvark  NW_006921694.1             21\n",
       "58        Koala  NW_018343957.1             21\n",
       "18  Alligator M  NW_017713851.1             20\n",
       "4       Aadvark  NW_006921697.1             19\n",
       "2       Aadvark  NW_006921691.1             16\n",
       "30    Chrysemys  NW_007281339.1             15\n",
       "26     Chelonia  NW_006646735.1             15\n",
       "13  Alligator M  NW_017707593.1             14\n",
       "5       Aadvark  NW_006921699.1             14\n",
       "70         Orca  NW_004438529.1             13\n",
       "87   Pelodiscus  NW_005871017.1             13\n",
       "88   Pelodiscus  NW_005871047.1             12\n",
       "97       Pogona  NW_018150745.1             12\n",
       "66         Orca  NW_004438436.1             11\n",
       "75      Ostrich  NW_009271620.1             11\n",
       "41        Devil  NW_003816605.1             11\n",
       "61        Koala  NW_018344103.1             11\n",
       "1       Aadvark  NW_006921649.1             10\n",
       "69         Orca  NW_004438483.1              9\n",
       "29     Chelonia  NW_006700040.1              9\n",
       "40        Devil  NW_003816604.1              9\n",
       "93       Pogona  NW_018150707.1              8\n",
       "37        Croco  NW_017728886.1              8\n",
       "36    Chrysemys  NW_007359863.1              7\n",
       "23     Chelonia  NW_006598898.1              7\n",
       "17  Alligator M  NW_017713772.1              7\n",
       "27     Chelonia  NW_006658951.1              7\n",
       "43        Devil  NW_003816613.1              6\n",
       "6       Aadvark  NW_006921825.1              6\n",
       "31    Chrysemys  NW_007281383.1              6\n",
       "99       Pogona  NW_018150815.1              6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = match_scaffold( 8, 'human', 'NC_000005.10', 5)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Specie\n",
       "Aadvark        NW_006921643.1\n",
       "Alligator M    NW_017712138.1\n",
       "Chelonia       NW_006646735.1\n",
       "Chrysemys      NW_007281339.1\n",
       "Croco          NW_017728909.1\n",
       "Devil          NW_003816605.1\n",
       "Gorilla           NC_018429.2\n",
       "Human            NC_000005.10\n",
       "Koala          NW_018343955.1\n",
       "Monodelphis       NC_008803.1\n",
       "Orca           NW_004438453.1\n",
       "Ostrich        NW_009271620.1\n",
       "Papio             NC_018157.1\n",
       "Pelodiscus     NW_005871017.1\n",
       "Pogona         NW_018150745.1\n",
       "Name: Scaffold, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc.groupby('Specie')['Scaffold'].first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load all of them at once and afterwards accessing one by one, this might be an option.\n",
    "#https://towardsdatascience.com/a-simple-trick-to-load-multiple-excel-worksheets-in-pandas-3fae4124345b\n",
    "# Define filepath\n",
    "filepath = '../Data/Raw/Tables_Filtered_IK_format.xlsx'\n",
    "\n",
    "# Load Excel file using Pandas with `sheet_name=None`\n",
    "df_dict = pd.read_excel(filepath, sheet_name=None)\n",
    "\n",
    "# Preview\n",
    "#df_dict\n",
    "\n",
    "# Get a specific one\n",
    "#human = df_dict.get('Human')\n",
    "\n",
    "# aprox 3 min 40 secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "460d27b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "LIFE97011 - Computing\n",
    "Python Programming - Assessed Exercise No. 3\n",
    "Task: Smith Waterman local alignment\n",
    "@Author: Slaviana Pavlovich\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Assigning the constants for the scores\n",
    "class Score(IntEnum):\n",
    "    # order by value it should be\n",
    "    MATCH = 10      \n",
    "    CONS_GAP = -2   # Want to penalize worst a first gap than a secong gap\n",
    "    FIRST_GAP = -4\n",
    "    MISMATCH = -3\n",
    "    #INV = 0\n",
    "    DUP = 1\n",
    "\n",
    "# Match: 10 , First_gap: -4, cons_gap: -1, mismatch: -5\n",
    "\n",
    "# Assigning the constant values for the traceback\n",
    "class Trace(IntEnum):\n",
    "    STOP = 0\n",
    "    LEFT = 1 \n",
    "    UP = 2\n",
    "    DIAGONAL = 3\n",
    "\n",
    "def excel_reader(specie):\n",
    "    data = pd.read_excel('../Data/Raw/Tables_Filtered_IK.xlsx', specie)\n",
    "    \n",
    "    data['Gene'] = data['Locus'].str.split('(\\d+)').str[0] + data['Strand']\n",
    "    data['Gene_non_or'] = data['Locus'].str.split('(\\d+)').str[0]\n",
    "    data.reset_index(inplace= True)\n",
    "\n",
    "    data = data[data['Gene'].str.contains('LOC') == False]  \n",
    "\n",
    "    return data\n",
    "\n",
    "# Implementing the Smith Waterman local alignment\n",
    "def smith_waterman(seq_1, seq_2):\n",
    "\n",
    "    # Data structure:\n",
    "    # 0: index\n",
    "    # 1: gen + orientation\n",
    "    # 2: gen\n",
    "\n",
    "    seq_1 = seq_1[['index', 'Gene', 'Gene_non_or']]\n",
    "    seq_2 = seq_2[['index', 'Gene', 'Gene_non_or']]\n",
    "\n",
    "    row = len(seq_1) + 1\n",
    "    col = len(seq_2) + 1\n",
    "    matrix = np.zeros(shape=(row, col), dtype= int)  \n",
    "    tracing_matrix = np.zeros(shape=(row, col), dtype= int)  \n",
    "\n",
    "    # Initialising the variables to find the highest scoring cell\n",
    "    max_score = -1\n",
    "    max_index = (-1, -1)\n",
    "\n",
    "    diagonal_score = 0\n",
    "    vertical_score = 0\n",
    "    horizontal_score = 0\n",
    "    \n",
    "    # Calculating the scores for all cells in the matrix\n",
    "\n",
    "    for i in range(1, row):\n",
    "        for j in range(1, col):\n",
    "            \n",
    "            # Calculating the diagonal score (match score)\n",
    "            # If there is a match, always win? And then, we can skip all further comparations?\n",
    "            match_value = Score.MATCH if seq_1.iloc[i - 1, 2] == seq_2.iloc[j - 1, 2] else Score.MISMATCH\n",
    "            #Score.INV if seq_1.iloc[i - 1, 2] == seq_2.iloc[j - 1, 2] else  --> No sense, it will make sense if the overall is inversed and then one of them is turned around. So, first, check the overall waz and then compare them.\n",
    "                \n",
    "            diagonal_score = matrix[i - 1, j - 1] + match_value\n",
    "\n",
    "            # Calculating the vertical gap score, penalizing less consecutive gaps and identifying duplicates\n",
    "            #if seq_2.iloc[j-1, 2] == seq_2.iloc[j - 2, 2]:\n",
    "                #vertical_score = matrix[i - 1, j] + Score.DUP elif\n",
    "            if matrix[i - 1, j] == vertical_score:\n",
    "                vertical_score = matrix[i - 1, j] + Score.CONS_GAP\n",
    "            else: vertical_score = matrix[i - 1, j] + Score.FIRST_GAP\n",
    "            \n",
    "            # Calculating the vertical gap score, penalizing consecutive gaps and identifying duplicates\n",
    "            #if seq_1.iloc[i-1, 2] == seq_1.iloc[i-2, 2]:\n",
    "                #horizontal_score = matrix[i, j - 1] + Score.DUP elif\n",
    "            if matrix[i, j - 1] == horizontal_score:\n",
    "                horizontal_score = matrix[i, j - 1] + Score.CONS_GAP\n",
    "            else: horizontal_score = matrix[i, j - 1] + Score.FIRST_GAP\n",
    "            \n",
    "            # Taking the highest score \n",
    "            matrix[i, j] = max(0, diagonal_score, vertical_score, horizontal_score)\n",
    "            \n",
    "            # Tracking where the cell's value is coming from    \n",
    "            if matrix[i, j] == 0: \n",
    "                tracing_matrix[i, j] = Trace.STOP\n",
    "                \n",
    "            elif matrix[i, j] == horizontal_score: \n",
    "                tracing_matrix[i, j] = Trace.LEFT\n",
    "                \n",
    "            elif matrix[i, j] == vertical_score: \n",
    "                tracing_matrix[i, j] = Trace.UP\n",
    "                \n",
    "            elif matrix[i, j] == diagonal_score: \n",
    "                tracing_matrix[i, j] = Trace.DIAGONAL \n",
    "                \n",
    "            # Tracking the cell with the maximum score\n",
    "            # If we want different strings, here we can define a threshold and keep track of all the higher values\n",
    "            if matrix[i, j] >= max_score:\n",
    "                max_index = (i,j)\n",
    "                max_score = matrix[i, j]\n",
    "\n",
    "\n",
    "    # Initialising the variables for tracing\n",
    "    aligned_seq_1 = [ ]\n",
    "    aligned_seq_2 = [ ]\n",
    "    index_seq_1 = [ ]\n",
    "    index_seq_2 = [ ]\n",
    "    (max_i, max_j) = max_index\n",
    "\n",
    "    # Tracing and computing the pathway with the local alignment\n",
    "    #if max_score > 3 * Score.MATCH\n",
    "    while tracing_matrix[max_i, max_j] != Trace.STOP:\n",
    "        if tracing_matrix[max_i, max_j] == Trace.DIAGONAL:\n",
    "            aligned_seq_1.insert(0, seq_1.iloc[max_i - 1, 2])\n",
    "            aligned_seq_2.insert(0, seq_2.iloc[max_j - 1, 2])\n",
    "\n",
    "            index_seq_1.insert(0, seq_1.iloc[max_i - 1, 0])\n",
    "            index_seq_2.insert(0, seq_2.iloc[max_j - 1, 0])\n",
    "\n",
    "            max_i = max_i - 1\n",
    "            max_j = max_j - 1\n",
    "            \n",
    "\n",
    "        elif tracing_matrix[max_i, max_j] == Trace.UP:\n",
    "            aligned_seq_1.insert(0, seq_1.iloc[max_i - 1, 2])\n",
    "            aligned_seq_2.insert(0, '-')\n",
    "\n",
    "            index_seq_1.insert(0, seq_1.iloc[max_i - 1, 0])\n",
    "            index_seq_2.insert(0, '-')\n",
    "\n",
    "            max_i = max_i - 1    \n",
    "            \n",
    "\n",
    "        elif tracing_matrix[max_i, max_j] == Trace.LEFT:\n",
    "            aligned_seq_1.insert(0, '-')\n",
    "            aligned_seq_2.insert(0, seq_2.iloc[max_j - 1, 2])\n",
    "\n",
    "            index_seq_1.insert(0, '-')\n",
    "            index_seq_2.insert(0, seq_2.iloc[max_j - 1, 0])\n",
    "            \n",
    "            max_j = max_j - 1\n",
    "\n",
    "    return aligned_seq_1, aligned_seq_2, index_seq_1, index_seq_2, max_score, max_index, max_i, max_j, matrix\n",
    "\n",
    "def duplicate(all):\n",
    "    for i in range(1, len(all)):\n",
    "        if all.loc[i, 'Result'] == 'Gap':\n",
    "            if (all.loc[i-1, 'Result'] == 'Match') | (all.loc[i-1, 'Result'] == 'Inversion'):\n",
    "                if (all.loc[i-1,'Query Sequence Gene'] == all.loc[i,'Query Sequence Gene']) | (all.loc[i-1,'Target Sequence Gene'] == all.loc[i,'Target Sequence Gene']):\n",
    "                    all.loc[i, 'Result'] = 'Duplicate'\n",
    "\n",
    "                    # Check for consecutives duplicates\n",
    "                    j = i+1\n",
    "                    while((j<len(all)) & (all.loc[j, 'Result'] == 'Gap') & (all.loc[i,'Query Sequence Gene'] == all.loc[j,'Query Sequence Gene']) & (all.loc[i,'Target Sequence Gene'] == all.loc[j,'Target Sequence Gene'])):\n",
    "                        all.loc[j, 'Result'] = 'Duplicate'\n",
    "                        j+=1\n",
    "                    i=j-1\n",
    "    return all\n",
    "\n",
    "def merge(seq_1, seq_2, aligned_seq_1, index_seq_1, aligned_seq_2, index_seq_2):\n",
    "    align_seq_1 = pd.DataFrame({'Original Position' : index_seq_1, 'Gene': aligned_seq_1}).merge(seq_1[['index', '#Replicon Name', 'Replicon Accession', 'Strand']], left_on = 'Original Position', right_on = 'index', how = 'left')\n",
    "    align_seq_2 = pd.DataFrame({'Original Position' : index_seq_2, 'Gene': aligned_seq_2}).merge(seq_2[['index', '#Replicon Name', 'Replicon Accession', 'Strand']], left_on = 'Original Position', right_on = 'index', how = 'left')\n",
    "\n",
    "    align_seq_1.rename(columns={'Original Position': 'Query Sequence Original Position', 'Gene' : 'Query Sequence Gene', '#Replicon Name': 'Query Sequence Replicon Name', 'Replicon Accession' : 'Query Sequence Replicon Accession', 'Strand': 'Query Sequence Orientation'}, inplace = True)\n",
    "    align_seq_2.rename(columns={'Original Position': 'Target Sequence Original Position', 'Gene' : 'Target Sequence Gene', '#Replicon Name': 'Target Sequence Replicon Name', 'Replicon Accession' : 'Target Sequence Replicon Accession', 'Strand': 'Target Sequence Orientation'}, inplace = True)\n",
    "\n",
    "    all = align_seq_1.loc[:, align_seq_1.columns != 'index'].merge(align_seq_2.loc[:, align_seq_2.columns != 'index'], right_index = True, left_index = True)\n",
    "\n",
    "    all['Result'] = np.where(all['Query Sequence Gene'] == all['Target Sequence Gene'],  \n",
    "                    np.where(all['Query Sequence Orientation'] == all['Target Sequence Orientation'], 'Match', 'Inversion'),\n",
    "                    np.where(((all['Query Sequence Gene'] == '-') | (all['Target Sequence Gene'] == '-')),\n",
    "                      'Gap', 'Mismatch'))\n",
    "    \n",
    "    all = all.reindex(\n",
    "            columns = ['Query Sequence Original Position', 'Query Sequence Replicon Name',\n",
    "            'Query Sequence Replicon Accession', 'Query Sequence Orientation', 'Query Sequence Gene', 'Result', 'Target Sequence Gene', 'Target Sequence Orientation',\n",
    "            'Target Sequence Replicon Accession', 'Target Sequence Replicon Name', 'Target Sequence Original Position'])\n",
    "\n",
    "    return all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning for each specie\n",
    "df_species = pd.DataFrame()\n",
    "\n",
    "species = df_dict.keys()\n",
    "\n",
    "for s in species:\n",
    "    aux = df_dict.get(s)\n",
    "    aux['Specie'] = s\n",
    "    df_species = pd.concat([df_species, aux])\n",
    "\n",
    "df_species['Gene'] = df_species['Locus'].str.split('(\\d+)').str[0] + df_species['Strand']\n",
    "df_species['Gene_non_or'] = df_species['Locus'].str.split('(\\d+)').str[0]\n",
    "df_species.reset_index(inplace= True)\n",
    "\n",
    "df_species = df_species[df_species['Gene'].str.contains('LOC') == False]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = match_scaffold( 8, 'human', 'NC_000005.10', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = acc.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pogona_NW_018150745.1\n",
      "Computed in 00:00:03\n",
      "Pogona_NW_018150707.1\n",
      "Computed in 00:00:03\n",
      "Pogona_NW_018150815.1\n",
      "Computed in 00:00:03\n",
      "Pelodiscus_NW_005871017.1\n",
      "Computed in 00:00:05\n",
      "Pelodiscus_NW_005871047.1\n",
      "Computed in 00:00:04\n",
      "Papio_NC_018157.1\n",
      "Computed in 00:01:01\n",
      "Ostrich_NW_009271620.1\n",
      "Computed in 00:00:04\n",
      "Orca_NW_004438453.1\n",
      "Computed in 00:00:06\n",
      "Orca_NW_004438462.1\n",
      "Computed in 00:00:03\n",
      "Orca_NW_004438529.1\n",
      "Computed in 00:00:02\n",
      "Orca_NW_004438436.1\n",
      "Computed in 00:00:03\n",
      "Orca_NW_004438483.1\n",
      "Computed in 00:00:02\n",
      "Monodelphis_NC_008803.1\n",
      "Computed in 00:02:18\n",
      "Monodelphis_NC_008801.1\n",
      "Computed in 00:03:50\n",
      "Koala_NW_018343955.1\n",
      "Computed in 00:00:10\n",
      "Koala_NW_018343957.1\n",
      "Computed in 00:00:05\n",
      "Koala_NW_018344103.1\n",
      "Computed in 00:00:02\n",
      "Gorilla_NC_018429.2\n",
      "Computed in 00:01:36\n",
      "Devil_NW_003816605.1\n",
      "Computed in 00:00:02\n",
      "Devil_NW_003816604.1\n",
      "Computed in 00:00:01\n",
      "Devil_NW_003816613.1\n",
      "Computed in 00:00:02\n",
      "Croco_NW_017728909.1\n",
      "Computed in 00:00:24\n",
      "Croco_NW_017728914.1\n",
      "Computed in 00:00:12\n",
      "Croco_NW_017728886.1\n",
      "Computed in 00:00:37\n",
      "Chrysemys_NW_007281339.1\n",
      "Computed in 00:00:05\n",
      "Chrysemys_NW_007359863.1\n",
      "Computed in 00:00:04\n",
      "Chrysemys_NW_007281383.1\n",
      "Computed in 00:00:02\n",
      "Chelonia_NW_006646735.1\n",
      "Computed in 00:00:01\n",
      "Chelonia_NW_006700040.1\n",
      "Computed in 00:00:02\n",
      "Chelonia_NW_006598898.1\n",
      "Computed in 00:00:02\n",
      "Chelonia_NW_006658951.1\n",
      "Computed in 00:00:01\n",
      "Alligator M_NW_017712138.1\n",
      "Computed in 00:00:13\n",
      "Alligator M_NW_017713851.1\n",
      "Computed in 00:00:10\n",
      "Alligator M_NW_017707593.1\n",
      "Computed in 00:00:08\n",
      "Alligator M_NW_017713772.1\n",
      "Computed in 00:00:06\n",
      "Aadvark_NW_006921643.1\n",
      "Computed in 00:00:05\n",
      "Aadvark_NW_006921953.1\n",
      "Computed in 00:00:02\n",
      "Aadvark_NW_006921694.1\n",
      "Computed in 00:00:02\n",
      "Aadvark_NW_006921697.1\n",
      "Computed in 00:00:02\n",
      "Aadvark_NW_006921691.1\n",
      "Computed in 00:00:01\n",
      "Aadvark_NW_006921699.1\n",
      "Computed in 00:00:02\n",
      "Aadvark_NW_006921649.1\n",
      "Computed in 00:00:01\n",
      "Aadvark_NW_006921825.1\n",
      "Computed in 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_specie = acc.iloc[0,1]\n",
    "target_scaffold = acc.iloc[0,2]\n",
    "\n",
    "target_seq = df_species[(df_species['Specie'] == target_specie) & (df_species['Replicon Accession'] == target_scaffold)]\n",
    "target_seq_name = target_specie + '_' + target_scaffold\n",
    "target_seq_or = target_seq\n",
    "\n",
    "# Save our results afterwards\n",
    "path = '../Data/S_W_Intermediate/Scaffold/' # + query_specie + '_' + target_specie + '_' + dt.now().strftime('%Y%m%d_%H%M%S') + '.xlsx'\n",
    "timestamp = dt.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = pd.ExcelWriter(path + target_specie + '_' + target_scaffold + '_' + timestamp + '.xlsx', engine = 'xlsxwriter')\n",
    "\n",
    "#os.makedirs(path)\n",
    "\n",
    "# Parameters\n",
    "params = []\n",
    "params = pd.DataFrame({\n",
    "    'Description': ['', 'Parameters', 'Match', 'Mismatch', 'First gap', 'Second gap'], \n",
    "    'Value': ['', '', Score.MATCH, Score.MISMATCH, Score.FIRST_GAP, Score.CONS_GAP]})\n",
    "\n",
    "results = []\n",
    "results = pd.DataFrame(data = {'Specie':'', 'Scaffold':'', '% Covered Target sequence':'', '% Covered Scaffold': '', 'Number of consecutive genes': ''})\n",
    "#results = pd.DataFrame(data = {'Accession', '% Covered Target sequence', '% Covered Accession', 'Number of consecutive genes'})\n",
    "\n",
    "acc = acc.drop(0).sort_values(['Specie', '# Appearances'], ascending=False)\n",
    "\n",
    "for i in range(0, len(acc)):\n",
    "    \n",
    "    if acc.iloc[i, 1] != acc.iloc[i-1, 1]:\n",
    "        target_seq = target_seq_or\n",
    "        \n",
    "    query_specie = acc.iloc[i, 1]\n",
    "    query_scaffold = acc.iloc[i,2]\n",
    "\n",
    "    query_seq = df_species.loc[(df_species['Specie'] == query_specie) & (df_species['Replicon Accession'] == query_scaffold)]\n",
    "    query_seq_name = query_specie + '_' + query_scaffold\n",
    "\n",
    "    print(query_seq_name)\n",
    "\n",
    "    # Executing the Smith Waterman local alignment algorithm\n",
    "    aligned_query_seq = []\n",
    "    aligned_target_seq = []\n",
    "    index_query_seq = []\n",
    "    index_target_seq = []\n",
    "    matrix = [[]]\n",
    "\n",
    "    tic = time.perf_counter()\n",
    "    aligned_query_seq, aligned_target_seq, index_query_seq, index_target_seq, max_score, max_index, max_i, max_j, matrix = smith_waterman(query_seq, target_seq)\n",
    "    toc = time.perf_counter()\n",
    "\n",
    "    # Time\n",
    "    d = toc - tic\n",
    "    print('Computed in %s'%time.strftime('%H:%M:%S', time.gmtime(d)))\n",
    "\n",
    "    all = []\n",
    "\n",
    "    all = merge(query_seq, target_seq, aligned_query_seq, index_query_seq, aligned_target_seq, index_target_seq)\n",
    "\n",
    "    all = duplicate(all)\n",
    "\n",
    "    index_query_seq_no_gaps = []\n",
    "    index_target_seq_no_gaps = []\n",
    "    index_query_seq_no_gaps = list(filter(lambda c: c!= '-', index_query_seq))\n",
    "    index_target_seq_no_gaps = list(filter(lambda c: c!= '-', index_target_seq))\n",
    "\n",
    "    summary = []\n",
    "    summary = pd.DataFrame({\n",
    "        'Description' : ['Query Sequence', 'Length Query Sequence', 'Target Sequence', 'Length Target Sequence', 'Score', '', 'Aligned Query Sequence initial position', 'Aligned Query Sequence final position', 'Aligned Query Sequence length', '', 'Aligned Target Sequence initial position', 'Aligned Target Sequence final position', 'Aligned Target Sequence length'],\n",
    "        'Value': [query_seq_name, len(query_seq), target_seq_name, len(target_seq), max_score, '', index_query_seq_no_gaps[0], \n",
    "                    index_query_seq_no_gaps[-1], index_query_seq_no_gaps[-1] - index_query_seq_no_gaps[0], '', index_target_seq_no_gaps[0], \n",
    "                    index_target_seq_no_gaps[-1], index_target_seq_no_gaps[-1] - index_target_seq_no_gaps[0]]\n",
    "    })\n",
    "\n",
    "    summary = pd.concat([summary, params])\n",
    "\n",
    "    aligned_query_seq_no_gaps = []\n",
    "    aligned_target_seq_no_gaps = []\n",
    "    aligned_query_seq_no_gaps = list(filter(lambda c: c!= '-', aligned_query_seq))\n",
    "    aligned_target_seq_no_gaps = list(filter(lambda c: c!= '-', aligned_target_seq)) \n",
    "\n",
    "    #KPIs\n",
    "    perc_align_query_seq = len(aligned_query_seq_no_gaps) / len(query_seq)\n",
    "    perc_align_target_seq = len(aligned_target_seq_no_gaps) / len(target_seq)\n",
    "\n",
    "    kpi = []\n",
    "    kpi = pd.DataFrame({\n",
    "        'Description': ['','KPIs','% Covered Target sequence', '% Covered Scaffold', 'Number of consecutive genes', ''], #include where duplicates occur\n",
    "        'Value': ['','', perc_align_target_seq, perc_align_query_seq, len(all), '']\n",
    "    })\n",
    "\n",
    "    result_perc = all.groupby('Result').count() / all.shape[0]\n",
    "    result_perc = result_perc.reset_index().iloc[:,[0,1]]\n",
    "    result_perc.rename(columns = {'Result':'Description', 'Query Sequence Original Position': 'Value'}, inplace=True)\n",
    "\n",
    "    summary = pd.concat([summary, kpi, result_perc]) # summary.append(kpi)\n",
    "\n",
    "    # Write\n",
    "    summary.to_excel(writer, sheet_name = 'Summary_' + query_scaffold, index = False, header=False)\n",
    "    all.to_excel(writer, sheet_name = 'Comparison_' + query_scaffold, index = False)\n",
    "\n",
    "    actual_results = pd.DataFrame(data = {'Specie':[query_specie], 'Scaffold': [query_scaffold], '% Covered Target sequence': [perc_align_target_seq], '% Covered Accession': [perc_align_query_seq], 'Number of consecutive genes': [len(all)]})\n",
    "                                \n",
    "    results = pd.concat([results, actual_results])\n",
    "    \n",
    "    heatmap = sns.heatmap(matrix)\n",
    "    plt.title('Heatmap of ' + target_seq_name + ' vs. ' + query_seq_name, fontsize = 12)\n",
    "    plt.savefig(path + 'Images/' + timestamp + '_' + query_seq_name + '.png')\n",
    "    plt.clf()\n",
    "\n",
    "    workbook  = writer.book\n",
    "    worksheet = writer.sheets['Summary_' + query_seq_name]\n",
    "    worksheet.insert_image('H2', path + 'Images/' + timestamp + '_' + query_seq_name + '.png')\n",
    "\n",
    "    # Remove match parts, when we have the same specie; and clean variables\n",
    "    prev = []\n",
    "    after = []\n",
    "    prev = target_seq.loc[target_seq['index'] < index_target_seq_no_gaps[0] + 1]\n",
    "    after = target_seq.loc[index_target_seq_no_gaps[-1] - 1 < target_seq['index']]\n",
    "\n",
    "    target_seq = pd.concat([prev, after])\n",
    "    del heatmap, perc_align_target_seq, perc_align_query_seq, result_perc\n",
    "\n",
    "results.to_excel(writer, sheet_name = 'Results', index = False)\n",
    "writer.sheets['Results'].activate()\n",
    "writer.save()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bertr\\anaconda3\\envs\\thesis\\lib\\site-packages\\xlsxwriter\\workbook.py:339: UserWarning: Calling close() on already closed file.\n",
      "  warn(\"Calling close() on already closed file.\")\n"
     ]
    }
   ],
   "source": [
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5109d816b82be14675a6b11f8e0f0d2e80f029176ed3710d54e125caa8520dfd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
